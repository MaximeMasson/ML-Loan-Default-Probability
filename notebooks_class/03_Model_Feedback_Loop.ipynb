{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f2bb8a",
   "metadata": {},
   "source": [
    "# 04 - Model Comparison\n",
    "\n",
    "### Goals:\n",
    "- Train and evaluate different models.\n",
    "- Compare model performance using metrics such as Accuracy, Precision, Recall, F1-score, and ROC-AUC.\n",
    "- Visualize results and select the best model for predicting loan default probability.\n",
    "\n",
    "## 1. Load Data and Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e034003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5500\n",
      "1    5500\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define data paths\n",
    "data_dir = '../data'\n",
    "processed_df_path = os.path.join(data_dir, 'processed_df.parquet')\n",
    "# processed_df = pd.read_parquet(\"../data/processed_df.parquet\", memory_map=False, engine=\"pyarrow\")\n",
    "processed_df = pd.read_parquet(\"/tmp/processed_df.parquet\")\n",
    "\n",
    "\n",
    "balanced_df = processed_df.groupby('target').sample(n=5500, random_state=42).reset_index(drop=True)\n",
    "print(balanced_df['target'].value_counts())\n",
    "\n",
    "nan_counts = balanced_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527b932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _Model_Comparator_class import modelComparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43fac2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Best Params': {'model__n_estimators': 304, 'model__learning_rate': 0.14235407208694828, 'model__random_state': 42}, 'Recall': 0.92, 'Precision': 0.8083067092651757, 'Accuracy': 0.850909090909091, 'F1 Score': 0.8605442176870748, 'AUC ROC': 0.8509090909090908, 'Model': 'adaboost', 'Processing Time (s)': 209.4823019504547}\n",
      "Testing model: gaussian_nb\n",
      "{'Best Params': {}, 'Recall': 0.9872727272727273, 'Precision': 0.6609860012172855, 'Accuracy': 0.7404545454545455, 'F1 Score': 0.7918337586584032, 'AUC ROC': 0.7404545454545455, 'Model': 'gaussian_nb', 'Processing Time (s)': 0.06160426139831543}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/onedrive/Documents ONEDRIVE/GitHub/Finance/Machine Learning - Loan Default Probability/notebooks_class/_Model_Comparator_class.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(self.metrics_dict, ignore_index=True)\n",
      "/mnt/onedrive/Documents ONEDRIVE/GitHub/Finance/Machine Learning - Loan Default Probability/notebooks_class/_Model_Comparator_class.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(self.metrics_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Model</th>\n",
       "      <th>Processing Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'model__penalty': 'l2', 'model__C': 1.8523547...</td>\n",
       "      <td>0.884545</td>\n",
       "      <td>0.806131</td>\n",
       "      <td>0.835909</td>\n",
       "      <td>0.843520</td>\n",
       "      <td>0.835909</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>48.498645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'model__n_estimators': 250, 'model__max_depth...</td>\n",
       "      <td>0.902727</td>\n",
       "      <td>0.822020</td>\n",
       "      <td>0.853636</td>\n",
       "      <td>0.860485</td>\n",
       "      <td>0.853636</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>257.482895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'model__n_estimators': 298, 'model__max_depth...</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.818690</td>\n",
       "      <td>0.862727</td>\n",
       "      <td>0.871599</td>\n",
       "      <td>0.862727</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>521.000919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'model__C': 0.30814016839651326, 'model__kern...</td>\n",
       "      <td>0.916364</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.834545</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.834545</td>\n",
       "      <td>svc</td>\n",
       "      <td>205.566595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'model__n_neighbors': 17, 'model__weights': '...</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.714662</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.727110</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>knn</td>\n",
       "      <td>35.727542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'model__n_estimators': 440, 'model__learning_...</td>\n",
       "      <td>0.918182</td>\n",
       "      <td>0.827869</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>972.399217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'model__n_estimators': 304, 'model__learning_...</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.808307</td>\n",
       "      <td>0.850909</td>\n",
       "      <td>0.860544</td>\n",
       "      <td>0.850909</td>\n",
       "      <td>adaboost</td>\n",
       "      <td>209.482302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.987273</td>\n",
       "      <td>0.660986</td>\n",
       "      <td>0.740455</td>\n",
       "      <td>0.791834</td>\n",
       "      <td>0.740455</td>\n",
       "      <td>gaussian_nb</td>\n",
       "      <td>0.061604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Best Params    Recall  Precision  \\\n",
       "0  {'model__penalty': 'l2', 'model__C': 1.8523547...  0.884545   0.806131   \n",
       "1  {'model__n_estimators': 250, 'model__max_depth...  0.902727   0.822020   \n",
       "2  {'model__n_estimators': 298, 'model__max_depth...  0.931818   0.818690   \n",
       "3  {'model__C': 0.30814016839651326, 'model__kern...  0.916364   0.787500   \n",
       "4  {'model__n_neighbors': 17, 'model__weights': '...  0.740000   0.714662   \n",
       "5  {'model__n_estimators': 440, 'model__learning_...  0.918182   0.827869   \n",
       "6  {'model__n_estimators': 304, 'model__learning_...  0.920000   0.808307   \n",
       "7                                                 {}  0.987273   0.660986   \n",
       "\n",
       "   Accuracy  F1 Score   AUC ROC                Model  Processing Time (s)  \n",
       "0  0.835909  0.843520  0.835909  logistic_regression            48.498645  \n",
       "1  0.853636  0.860485  0.853636              xgboost           257.482895  \n",
       "2  0.862727  0.871599  0.862727        random_forest           521.000919  \n",
       "3  0.834545  0.847059  0.834545                  svc           205.566595  \n",
       "4  0.722273  0.727110  0.722273                  knn            35.727542  \n",
       "5  0.863636  0.870690  0.863636    gradient_boosting           972.399217  \n",
       "6  0.850909  0.860544  0.850909             adaboost           209.482302  \n",
       "7  0.740455  0.791834  0.740455          gaussian_nb             0.061604  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_test = ['logistic_regression', 'xgboost', 'random_forest', 'svc', 'knn', 'gradient_boosting', 'adaboost', 'gaussian_nb']\n",
    "\n",
    "model_comparator = modelComparator(balanced_df)\n",
    "model_comparator.compare_models(model_to_test, kfolds=10, n_trials=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa5d6a1",
   "metadata": {},
   "source": [
    "In the model comparison, the gradient boosting model achieved the highest performance with an AUC ROC of 0.865, recall of 0.938, and an F1 score of 0.874, despite a processing time of 1108 seconds. The xgboost and random forest models also performed well with AUC ROC scores of 0.8627 and 0.8623, respectively. Logistic regression and SVC had lower recall and AUC ROC values around 0.835. KNN and Gaussian NB showed significantly lower scores across metrics, indicating limited effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263754f",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad1bd73",
   "metadata": {},
   "source": [
    "We create new features with financial logics based on existing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_df = balanced_df.copy()\n",
    "\n",
    "# Debt-to-Income Adjusted Ratio\n",
    "new_feature_df['dti_adjusted'] = new_feature_df['dti'] + (new_feature_df['annual_inc'] / new_feature_df['annual_inc'].mean())\n",
    "\n",
    "# Income-to-Loan Ratio\n",
    "new_feature_df['income_to_loan'] = new_feature_df['annual_inc'] / new_feature_df['loan_amnt']\n",
    "\n",
    "# Income per Installment\n",
    "new_feature_df['income_per_installment'] = new_feature_df['annual_inc'] / new_feature_df['installment']\n",
    "\n",
    "# Loan Amount Percentile\n",
    "new_feature_df['loan_amount_percentile'] = pd.qcut(new_feature_df['loan_amnt'], 10, labels=False)\n",
    "\n",
    "# Installment-to-Income Ratio\n",
    "new_feature_df['installment_to_income'] = new_feature_df['installment'] / (new_feature_df['annual_inc'] / 12)\n",
    "\n",
    "# Repayment Progress (assuming 'out_prncp' is available as outstanding principal)\n",
    "new_feature_df['repayment_progress'] = 1 - (new_feature_df['last_pymnt_amnt'] / new_feature_df['loan_amnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37a501f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Best Params': {'model__n_estimators': 448, 'model__learning_rate': 0.9883477038666212, 'model__random_state': 42}, 'Recall': 0.9172727272727272, 'Precision': 0.8401332223147377, 'Accuracy': 0.8713636363636363, 'F1 Score': 0.8770099956540635, 'AUC ROC': 0.8713636363636363, 'Model': 'adaboost', 'Processing Time (s)': 427.5174045562744}\n",
      "Testing model: gaussian_nb\n",
      "{'Best Params': {}, 'Recall': 0.9845454545454545, 'Precision': 0.7273337810611148, 'Accuracy': 0.8077272727272727, 'F1 Score': 0.8366164542294322, 'AUC ROC': 0.8077272727272726, 'Model': 'gaussian_nb', 'Processing Time (s)': 0.06751108169555664}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/onedrive/Documents ONEDRIVE/GitHub/Finance/Machine Learning - Loan Default Probability/notebooks_class/_Model_Comparator_class.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(self.metrics_dict, ignore_index=True)\n",
      "/mnt/onedrive/Documents ONEDRIVE/GitHub/Finance/Machine Learning - Loan Default Probability/notebooks_class/_Model_Comparator_class.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(self.metrics_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Model</th>\n",
       "      <th>Processing Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'model__penalty': 'l1', 'model__C': 0.1051764...</td>\n",
       "      <td>0.913636</td>\n",
       "      <td>0.810484</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>49.946633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'model__n_estimators': 350, 'model__max_depth...</td>\n",
       "      <td>0.960909</td>\n",
       "      <td>0.928822</td>\n",
       "      <td>0.943636</td>\n",
       "      <td>0.944593</td>\n",
       "      <td>0.943636</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>540.600020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'model__n_estimators': 297, 'model__max_depth...</td>\n",
       "      <td>0.948182</td>\n",
       "      <td>0.906169</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.926699</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>967.051095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'model__C': 0.21767257562818648, 'model__kern...</td>\n",
       "      <td>0.941818</td>\n",
       "      <td>0.792049</td>\n",
       "      <td>0.847273</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.847273</td>\n",
       "      <td>svc</td>\n",
       "      <td>290.485037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'model__n_neighbors': 19, 'model__weights': '...</td>\n",
       "      <td>0.816364</td>\n",
       "      <td>0.755892</td>\n",
       "      <td>0.776364</td>\n",
       "      <td>0.784965</td>\n",
       "      <td>0.776364</td>\n",
       "      <td>knn</td>\n",
       "      <td>60.502779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'model__n_estimators': 170, 'model__learning_...</td>\n",
       "      <td>0.957273</td>\n",
       "      <td>0.934339</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.945667</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>1091.760772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'model__n_estimators': 448, 'model__learning_...</td>\n",
       "      <td>0.917273</td>\n",
       "      <td>0.840133</td>\n",
       "      <td>0.871364</td>\n",
       "      <td>0.877010</td>\n",
       "      <td>0.871364</td>\n",
       "      <td>adaboost</td>\n",
       "      <td>427.517405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.984545</td>\n",
       "      <td>0.727334</td>\n",
       "      <td>0.807727</td>\n",
       "      <td>0.836616</td>\n",
       "      <td>0.807727</td>\n",
       "      <td>gaussian_nb</td>\n",
       "      <td>0.067511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Best Params    Recall  Precision  \\\n",
       "0  {'model__penalty': 'l1', 'model__C': 0.1051764...  0.913636   0.810484   \n",
       "1  {'model__n_estimators': 350, 'model__max_depth...  0.960909   0.928822   \n",
       "2  {'model__n_estimators': 297, 'model__max_depth...  0.948182   0.906169   \n",
       "3  {'model__C': 0.21767257562818648, 'model__kern...  0.941818   0.792049   \n",
       "4  {'model__n_neighbors': 19, 'model__weights': '...  0.816364   0.755892   \n",
       "5  {'model__n_estimators': 170, 'model__learning_...  0.957273   0.934339   \n",
       "6  {'model__n_estimators': 448, 'model__learning_...  0.917273   0.840133   \n",
       "7                                                 {}  0.984545   0.727334   \n",
       "\n",
       "   Accuracy  F1 Score   AUC ROC                Model  Processing Time (s)  \n",
       "0  0.850000  0.858974  0.850000  logistic_regression            49.946633  \n",
       "1  0.943636  0.944593  0.943636              xgboost           540.600020  \n",
       "2  0.925000  0.926699  0.925000        random_forest           967.051095  \n",
       "3  0.847273  0.860465  0.847273                  svc           290.485037  \n",
       "4  0.776364  0.784965  0.776364                  knn            60.502779  \n",
       "5  0.945000  0.945667  0.945000    gradient_boosting          1091.760772  \n",
       "6  0.871364  0.877010  0.871364             adaboost           427.517405  \n",
       "7  0.807727  0.836616  0.807727          gaussian_nb             0.067511  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_test = ['logistic_regression', 'xgboost', 'random_forest', 'svc', 'knn', 'gradient_boosting', 'adaboost', 'gaussian_nb']\n",
    "\n",
    "model_comparator_new_feature = modelComparator(new_feature_df)\n",
    "model_comparator_new_feature.compare_models(model_to_test, kfolds=10, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c411e553",
   "metadata": {},
   "source": [
    "After feature engineering, the AUC ROC scores improved for all models, particularly boosting algorithms. Gradient Boosting’s AUC ROC jumped significantly from 0.865 to 0.943. This improvement highlights how feature engineering added valuable information that allowed Gradient Boosting to capture complex patterns more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252353a0",
   "metadata": {},
   "source": [
    "## 3. Feature Selection\n",
    "Because Gradient Boosting is the most effficient we will focuse our attention on this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc27c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_to_test = ['gradient_boosting']\n",
    "\n",
    "model_comparator_best_param = modelComparator(new_feature_df)\n",
    "model_comparator_best_param.compare_models(model_to_test, kfolds=10, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b3036",
   "metadata": {},
   "source": [
    "\n",
    "Next, we’ll examine the feature importance scores to identify the most influential features in our models. By selecting only the features with an importance score above 1%, we can refine the dataset, focusing on the most predictive elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bad7e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'modelComparator' object has no attribute 'best_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Access the Gradient Boosting model from the pipeline\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m gradient_boosting_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_comparator_best_param\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get the feature importances and feature names\u001b[39;00m\n\u001b[1;32m      6\u001b[0m importances \u001b[38;5;241m=\u001b[39m gradient_boosting_model\u001b[38;5;241m.\u001b[39mfeature_importances_\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'modelComparator' object has no attribute 'best_model'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Access the Gradient Boosting model from the pipeline\n",
    "gradient_boosting_model = model_comparator_best_param.best_model.named_steps['model']\n",
    "\n",
    "# Get the feature importances and feature names\n",
    "importances = gradient_boosting_model.feature_importances_\n",
    "feature_names = model_comparator_best_param.X_train.columns\n",
    "\n",
    "# Create a DataFrame for easy sorting and filtering\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter for the top features\n",
    "filtered_feature_importance = importance_df[importance_df['Importance'] > 0.01].set_index('Feature')['Importance'].to_dict()\n",
    "\n",
    "print(f'Number of features initially: {importance_df.shape[0]}')\n",
    "print(f'Number of features after selection: {len(filtered_feature_importance)}')\n",
    "\n",
    "# Plot the filtered feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(list(filtered_feature_importance.keys()), list(filtered_feature_importance.values()), color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importance for Gradient Boosting Model in Pipeline\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd62671c",
   "metadata": {},
   "source": [
    "After evaluating the feature importance scores, we found that we started with 60 features initially. Following our selection process, we narrowed it down to just 8 features with an importance score greater than 1%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55f981",
   "metadata": {},
   "source": [
    "We train the model again to see if there is an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of keys from filtered_feature_importance\n",
    "feature_keys = list(filtered_feature_importance.keys())\n",
    "\n",
    "feature_selec_df = new_feature_df[['target'] + feature_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_test = ['gradient_boosting']\n",
    "model_comparator_feature_selec = modelComparator(feature_selec_df)\n",
    "model_comparator_feature_selec.compare_models(model_to_test, 10, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4145c5",
   "metadata": {},
   "source": [
    "After applying feature selection, the performance of our Gradient Boosting model improved significantly. Initially, with 60 features, the model achieved an Accuracy of 0.943182. Following the selection process, where we reduced the feature set to just 8 important features, the model's Accuracy increased to 0.959545."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14856ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_selec_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mfeature_selec_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_parquet(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_selec_df.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Save the best model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_selec_df' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "feature_selec_df.to_parquet(os.path.join(data_dir, 'feature_selec_df.parquet'))\n",
    "\n",
    "# Save the best model\n",
    "model_dir = 'model'\n",
    "model_path = os.path.join(model_dir, 'best_gradient_boosting_model.joblib')\n",
    "joblib.dump(model_comparator_feature_selec.best_model, model_path)\n",
    "\n",
    "print(f'Model saved to {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda687e",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "- The best model based on evaluation metrics is identified.\n",
    "- Future improvements may include hyperparameter tuning or additional feature engineering.\n",
    "- Further steps: Deploy the best model for production use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
